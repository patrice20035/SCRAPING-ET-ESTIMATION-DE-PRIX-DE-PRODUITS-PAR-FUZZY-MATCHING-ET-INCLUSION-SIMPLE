{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f68e8a-fb6b-476e-86d0-670c07b069eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like to analyze promotions or products [promotions/products]?  promotions\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 278\u001b[0m\n\u001b[0;32m    275\u001b[0m     save_viz(top_brands, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProducts per brands (Top 10)  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 278\u001b[0m     n\u001b[38;5;241m=\u001b[39mpages_number_promotions(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.carrefour.fr/promotions?noRedirect=0&page=0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    279\u001b[0m     df_final\u001b[38;5;241m=\u001b[39mscrapping_promotions()\n\u001b[0;32m    280\u001b[0m     df_final\u001b[38;5;241m=\u001b[39mresetting_index(df_final)\n",
      "Cell \u001b[1;32mIn[2], line 84\u001b[0m, in \u001b[0;36mpages_number_promotions\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# i = number of products promoted\u001b[39;00m\n\u001b[0;32m     83\u001b[0m number\u001b[38;5;241m=\u001b[39m[i\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 84\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(number[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# checking number of product per page\u001b[39;00m\n\u001b[0;32m     86\u001b[0m product_name\u001b[38;5;241m=\u001b[39m[i\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul h2\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "# import libraries\n",
    "import requests as r\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Defining functions\n",
    "\n",
    "#What do we scrap:\n",
    "def type_scrapping():\n",
    "    type_scrapping=['promotions', 'products']\n",
    "    while True:\n",
    "        scrap=input('Would you like to analyze promotions or products [promotions/products]? ',)\n",
    "        if scrap in type_scrapping:\n",
    "            break\n",
    "    return scrap\n",
    "\n",
    "#Defining which category to scrap if products\n",
    "def cat_name():\n",
    "    print(r\"\"\"The categories are:\n",
    "    - bio-et-ecologie\n",
    "    - fruits-et-legumes\n",
    "    - viandes-et-poissons\n",
    "    - pains-et-patisseries\n",
    "    - cremerie\n",
    "    - traiteur\n",
    "    - surgeles\n",
    "    - epicerie-salee\n",
    "    - epicerie-sucree\n",
    "    - hygiene-et-beaute\n",
    "    - boissons-sans-alcool\n",
    "    - alcools-et-produits-aperitifs\n",
    "    - hygiene-et-beaute\n",
    "    - entretien-et-nettoyage\n",
    "    - animaux\n",
    "    - le-monde-de-bebe\n",
    "    - jardin-outdoor\n",
    "    - maison-interieur\n",
    "    - cuisine-et-arts-de-la-table\n",
    "    - electromenager\n",
    "    - bricolage-auto\n",
    "    - beaute-entretien-et-proprete\n",
    "    - bagagerie-sport-et-loisirs\n",
    "    - telephonie-et-objets-connectes\n",
    "    - image-et-son\n",
    "    - informatique-bureau\n",
    "    - culture-et-jeux-videos\n",
    "    - jeux-et-jouets\n",
    "    \"\"\")\n",
    "    list_cat=['bio-et-ecologie','fruits-et-legumes','viandes-et-poissons', 'pains-et-patisseries','cremerie','traiteur','surgeles','epicerie-salee','epicerie-sucree','hygiene-et-beaute','boissons-sans-alcool','alcools-et-produits-aperitifs','hygiene-et-beaute','entretien-et-nettoyage','animaux','le-monde-de-bebe','jardin-outdoor','maison-interieur','cuisine-et-arts-de-la-table','electromenager','bricolage-auto','beaute-entretien-et-proprete','bagagerie-sport-et-loisirs','telephonie-et-objets-connectes','image-et-son','informatique-bureau','culture-et-jeux-videos','jeux-et-jouets']\n",
    "    while True:\n",
    "        cat_name=input('What category would you like to scrap? ',)\n",
    "        if cat_name in list_cat:\n",
    "            break\n",
    "    return cat_name\n",
    "\n",
    "\n",
    "\n",
    "#Finding how many pages need to be scrapped\n",
    "def pages_number_products(cat_name):\n",
    "    url=f\"https://www.carrefour.fr/r/{cat_name}?noRedirect=1&page=0\"\n",
    "    html = r.get(url).content;\n",
    "    soup = BeautifulSoup(html)\n",
    "    # i = number of products promoted\n",
    "    number=[i.text.replace('\\n','') for i in soup.select('h5')]\n",
    "    i=int(number[0].split()[0])\n",
    "    # checking number of product per page\n",
    "    product_name=[i.text.replace('\\n','') for i in soup.select('ul h2')]\n",
    "    # n = number of pages of promo\n",
    "    n=math.ceil(i/len(product_name))\n",
    "    return n\n",
    "\n",
    "#Finding how many pages need to be scrapped\n",
    "def pages_number_promotions(url):\n",
    "    html = r.get(url).content;\n",
    "    soup = BeautifulSoup(html)\n",
    "    # i = number of products promoted\n",
    "    number=[i.text.replace('\\n','') for i in soup.select('h5')]\n",
    "    i=int(number[0].split()[0])\n",
    "    # checking number of product per page\n",
    "    product_name=[i.text.replace('\\n','') for i in soup.select('ul h2')]\n",
    "    # n = number of pages of promo\n",
    "    n=math.ceil(i/len(product_name))\n",
    "    return n\n",
    "\n",
    "#Scrapping pages\n",
    "def scrapping_products():\n",
    "    df_final=pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        url=f'https://www.carrefour.fr/r/{cat_name}?noRedirect=1&page={i+1}'\n",
    "        headers=f\"\"\"accept: application/json, text/plain, */*\n",
    "        accept-encoding: gzip, deflate, br\n",
    "        accept-language: fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\n",
    "        cache-control: no-cache\n",
    "        cookie: TCPID=119551614271772534656; _ga=GA1.2.1334375845.1556892869; cookieIDCrfOne=V12019531614280.2021166067845266; TC_OPTOUT=0@@@@@@ALL; already_visitedOne=1; visid_incap_1982952=0RjOMFJXRuKKO5znr4FgKeRMzFwAAAAAQUIPAAAAAAD6n2mvQU/sqwDmJkARHJBk; tc_cj_v2=m_iZZZ%22**%22%27%20ZZZKOOPRSLRPQNRRZZZ%5D777_rn_lh%5BfyfcheZZZ222H.*-/%24-%7B+%7B-%24.H%7D*%28ZZZKOOQLKRRRQLLMZZZ%5D777m_iZZZ%22**%22%27%20ZZZKOQRKMKMSQNRKZZZ%5D; datadome=MV~uTOOCnVIzfg.ULn2qjQwiYrYCKiCPqVlIXhkojIZNBB1zJzAjb_LCHT2CCYufdPeKF5Omu7~Z9jwshB52Hgn-fgLks.1wkrj4LccckQ; _cs_c=0; _cs_id=9566bfd8-1a78-a240-f0bb-e8015b3551ba.1556892869.3.1578131399.1578131399.1.1591056869072; visid_incap_441619=vrnUei+7RLiL2Xr3UUmTzfgij14AAAAAQUIPAAAAAABOtZUZlXTnCzjXe1PMdHUQ; visid_incap_1722501=z8YspOTjRLmNxY1jMdqc2voij14AAAAAQUIPAAAAAAAz5k9o0TPe5INp8+VLBGMZ; FRONTONE_USER=1589030911; FRONTONE_SESSID=b63750e3dfbafa4034d6cf3e8d2d558c; FRONTONE_SESSION_ID=e63380316c097c37050207ec718741fff9259edc; nlbi_441619=hPsnDNGFBgcuMoocJv8P3AAAAADvRtLIitBw0DCDaulsolSv; incap_ses_766_441619=xOrCJJ75ZFMuHdRpFmKhCqARk14AAAAAAbkGgZaI3ZwKzWSE9YLNdw==; incap_ses_766_1722501=V7G5dFZNVT+iJNRpFmKhCrsRk14AAAAAXCoyqmHLrIAbZR4ql84New==; QueueITAccepted-SDFrts345E-V3_prodevent=EventId%3Dprodevent%26QueueId%3D353322c4-4a85-4736-95aa-c51441010113%26RedirectType%3Dsafetynet%26IssueTime%3D1586696637%26Hash%3Df43739e176b3b7aaa718bb08ec22f99ce1e1414fc95bb20a6472efd106b12563; visid_incap_2237321=MIUgPDc1SUulJogUgHnXuewRk14AAAAAQUIPAAAAAACC1NtTLjWHs8UOS/4WjTEn; incap_ses_766_2237321=r+MCOZqfWyiAMtRpFmKhCuwRk14AAAAA3H8Vhks4p1T4AV7SEIzY0A==; ABTasty=uid%3D20041215043664510%26fst%3D1586696676950%26pst%3Dnull%26cst%3D1586696676950%26ns%3D1%26pvt%3D18%26pvis%3D18%26th%3D562227.699323.18.18.1.1.1586696677071.1586696730088.1_573142.710608.17.17.1.1.1586696677090.1586696730101.1_575385.713246.17.17.1.1.1586696677179.1586696730128.1; ab-popin_solutions=1; ABTastySession=sen%3D110__referrer%3Dhttps%3A//www.carrefour.fr/r%3Ffilters%255Bproduct.categories.name%255D%255B0%255D%3DEntretien%2520et%2520nettoyage%26noRedirect%3D0__landingPage%3Dhttps%3A//www.carrefour.fr/r/alcools-et-produits-aperitifs__referrerSent%3Dtrue; ADRUM=s=1586696878563&r=https%3A%2F%2Fwww.carrefour.fr%2Fboutique%2Fparapharmacie%3F0; pageCounterCrfOne=46\n",
    "        dnt: 1\n",
    "        pragma: no-cache\n",
    "        referer: https://www.carrefour.fr/r/{cat_name}?noRedirect=1&page={i+1}\n",
    "        sec-fetch-dest: empty\n",
    "        sec-fetch-mode: cors\n",
    "        sec-fetch-site: same-origin\n",
    "        user-agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36 OPR/117.0.0.0\n",
    "        x-requested-with: XMLHttpRequest\"\"\"\n",
    "        headers=dict([i.strip().split(': ') for i in headers.split('\\n')])\n",
    "        results=r.get(url, headers=headers).json()\n",
    "        df=pd.json_normalize(results['data'])\n",
    "        df1 = df[['attributes.ean','attributes.title', 'attributes.brand',  'attributes.categories','attributes.availability.purchasable', 'attributes.price.price', 'attributes.price.perUnitLabel']]\n",
    "        df_final=df_final.append(df1)\n",
    "        time.sleep(4)\n",
    "        print(i)\n",
    "    return df_final\n",
    "\n",
    "#Scrapping pages\n",
    "def scrapping_promotions():\n",
    "    df_final=pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        url=f\"https://www.carrefour.fr/promotions?noRedirect=0&page={i+1}\"\n",
    "        headers=f\"\"\"accept: application/json, text/plain, */*\n",
    "        accept-encoding: gzip, deflate, br\n",
    "        accept-language: fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\n",
    "        cache-control: no-cache\n",
    "        cookie: TCPID=119551614271772534656; _ga=GA1.2.1334375845.1556892869; cookieIDCrfOne=V12019531614280.2021166067845266; TC_OPTOUT=0@@@@@@ALL; already_visitedOne=1; visid_incap_1982952=0RjOMFJXRuKKO5znr4FgKeRMzFwAAAAAQUIPAAAAAAD6n2mvQU/sqwDmJkARHJBk; tc_cj_v2=m_iZZZ%22**%22%27%20ZZZKOOPRSLRPQNRRZZZ%5D777_rn_lh%5BfyfcheZZZ222H.*-/%24-%7B+%7B-%24.H%7D*%28ZZZKOOQLKRRRQLLMZZZ%5D777m_iZZZ%22**%22%27%20ZZZKOQRKMKMSQNRKZZZ%5D; datadome=MV~uTOOCnVIzfg.ULn2qjQwiYrYCKiCPqVlIXhkojIZNBB1zJzAjb_LCHT2CCYufdPeKF5Omu7~Z9jwshB52Hgn-fgLks.1wkrj4LccckQ; _cs_c=0; _cs_id=9566bfd8-1a78-a240-f0bb-e8015b3551ba.1556892869.3.1578131399.1578131399.1.1591056869072; visid_incap_441619=vrnUei+7RLiL2Xr3UUmTzfgij14AAAAAQUIPAAAAAABOtZUZlXTnCzjXe1PMdHUQ; visid_incap_1722501=z8YspOTjRLmNxY1jMdqc2voij14AAAAAQUIPAAAAAAAz5k9o0TPe5INp8+VLBGMZ; FRONTONE_USER=1589030911; FRONTONE_SESSID=b63750e3dfbafa4034d6cf3e8d2d558c; FRONTONE_SESSION_ID=e63380316c097c37050207ec718741fff9259edc; nlbi_441619=ufhBSxHyMEoXfsE3Jv8P3AAAAABTP2fpV1zP/JtDBdulhzAa; incap_ses_766_441619=MtovSnQkoT9/JNpoFmKhCqEbkF4AAAAAc7N3y/70ukqqav4TtYvpDQ==; pageCounterCrfOne=1; QueueITAccepted-SDFrts345E-V3_prodevent=EventId%3Dprodevent%26QueueId%3D54e303e1-7614-444d-8c92-dbdad2d61b4a%26RedirectType%3Dsafetynet%26IssueTime%3D1586502577%26Hash%3D21030c8a62ca512d24f5dcbcaacc1f41b3c042a6999d987071870a39842d6678\n",
    "        dnt: 1\n",
    "        pragma: no-cache\n",
    "        referer: https://www.carrefour.fr/promotions?noRedirect=1&page={i+1}\n",
    "        sec-fetch-dest: empty\n",
    "        sec-fetch-mode: cors\n",
    "        sec-fetch-site: same-origin\n",
    "        user-agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36 OPR/117.0.0.0\n",
    "        x-requested-with: XMLHttpRequest\"\"\"\n",
    "        headers=dict([i.strip().split(': ') for i in headers.split('\\n')])\n",
    "        results=r.get(url, headers=headers).json()\n",
    "        df=pd.json_normalize(results['data'])\n",
    "        df['difference'] = df['attributes.promotion.messageArgs.initialPrice'] - df['attributes.promotion.messageArgs.discountedPrice']\n",
    "        df1 = df[['attributes.ean','attributes.title', 'attributes.brand',  'attributes.categories','attributes.availability.purchasable', 'attributes.promotion.label', 'attributes.promotion.bestQuantity', 'attributes.promotion.messageArgs.discountedPrice','attributes.promotion.messageArgs.initialPrice', 'difference', 'attributes.promotion.discountLabel','attributes.price.perUnitLabel','attributes.promotion.promoStartDate','attributes.promotion.promoEndDate']]\n",
    "        df_final=df_final.append(df1)\n",
    "        time.sleep(2)\n",
    "        print(i)\n",
    "    return df_final\n",
    "    \n",
    "def resetting_index(df_final):\n",
    "    df_final=df_final.reset_index() \n",
    "    df_final.rename(columns={\"index\":\"old_index\"})\n",
    "    return df_final\n",
    "\n",
    "#cleaning data\n",
    "def clean_cat(df_final):\n",
    "\n",
    "    categories=[]\n",
    "\n",
    "    for k in df_final.index:\n",
    "        if df_final['attributes.categories'][k] == None:\n",
    "            df_final['attributes.categories'][k] = [{'id': 'NA',\n",
    "      'slug': 'NA',\n",
    "      'label': ' Not specified',\n",
    "      'uri': 'NA'},\n",
    "     {'id': 'NA',\n",
    "      'slug': 'NA',\n",
    "      'label': 'Not specified',\n",
    "      'uri': 'NA'},\n",
    "     {'id': 'NA',\n",
    "      'slug': 'NA',\n",
    "      'label': 'Not specified',\n",
    "      'uri': 'NA'}]\n",
    "\n",
    "        categories.append([i['label'] for i in df_final['attributes.categories'][k]])\n",
    "        category=[i[0] for i in categories]\n",
    "        subcategory=[i[1] for i in categories]\n",
    "    df_final['category']=category\n",
    "    df_final['subcategory']=subcategory\n",
    "    df_final=df_final.drop(['attributes.categories'], axis=1)\n",
    "    return df_final\n",
    "\n",
    "#renaming col\n",
    "def renaming_col_products(df_final):\n",
    "    df_ok=df_final.rename(columns={\"attributes.ean\": \"EAN\", \"attributes.title\": \"product_name\", 'attributes.brand':'brand', 'attributes.availability.purchasable':'purchasable', 'attributes.price.perUnitLabel':'price_per_unit','attributes.price.price':'price'})\n",
    "    df_ok=df_ok[['EAN', 'product_name', 'brand', 'category', 'subcategory', 'purchasable', 'price', 'price_per_unit']]\n",
    "    return df_ok\n",
    "\n",
    "#renaming col\n",
    "def renaming_col_promotions(df_final):\n",
    "    df_ok=df_final.rename(columns={\"attributes.ean\": \"EAN\", \"attributes.title\": \"product_name\", 'attributes.brand':'brand', 'attributes.availability.purchasable':'purchasable', 'attributes.promotion.label':'promotion_type', 'attributes.promotion.bestQuantity': 'best_quantity', 'attributes.promotion.messageArgs.discountedPrice': 'discounted_price', 'attributes.promotion.messageArgs.initialPrice':'initial_price', 'attributes.promotion.discountLabel':'promo_description','attributes.price.perUnitLabel':'price_per_unit','attributes.promotion.promoStartDate':'Start_Date', 'attributes.promotion.promoEndDate':'End_Date'   })\n",
    "    df_ok=df_ok[['EAN', 'product_name', 'brand', 'category', 'subcategory', 'purchasable', 'promotion_type', 'promo_description', 'best_quantity','price_per_unit', 'discounted_price', 'initial_price', 'difference','Start_Date','End_Date']]\n",
    "    return df_ok\n",
    "\n",
    "# data analysis\n",
    "def group_category_products(df_final):\n",
    "    df_final.groupby('category').mean()\n",
    "    df_group=df_final.groupby(['category','subcategory']).count()['EAN']\n",
    "    df_group=pd.DataFrame(df_group).rename(columns={'EAN':'count_products'})\n",
    "    return df_group\n",
    "\n",
    "# data analysis\n",
    "def group_category_promotions(df_final):\n",
    "    df_final.groupby('category').mean()\n",
    "    df_group=df_final.groupby(['category','subcategory']).count()['EAN']\n",
    "    df_group=pd.DataFrame(df_group).rename(columns={'EAN':'count_promotion'})\n",
    "    return df_group\n",
    "\n",
    "\n",
    "# save final df into a csv\n",
    "def save_df_products():\n",
    "    os.chdir('C:/Users/DELL/OneDrive - etu.unistra.fr/Bureau/cours fac/PROGRAMMATION PYTHON/PROJET/Output')\n",
    "    df_final.to_csv(f'Carrefour_products_{cat_name}.csv')\n",
    "    \n",
    "\n",
    "# save final df into a csv\n",
    "def save_df_promotions():\n",
    "    os.chdir('C:/Users/DELL/OneDrive - etu.unistra.fr/Bureau/cours fac/PROGRAMMATION PYTHON/PROJET/Output')\n",
    "    df_final.to_csv('Carrefour_promo.csv')\n",
    "\n",
    "#creating graphs\n",
    "    \n",
    "def graph_subcat_products():\n",
    "    df_subcategory=pd.DataFrame(df_final.subcategory.value_counts()).reset_index().rename(columns={'index':'Subcategory', 'subcategory':'Number of Products'})\n",
    "    fig, ax = plt.subplots(figsize=(40,15))\n",
    "    graph_subcat = sns.barplot(data=df_subcategory, x='Subcategory', y='Number of Products')\n",
    "    plt.title('Products per category'+ f' {cat_name}'+'\\n', fontsize=30)\n",
    "    return graph_subcat\n",
    "\n",
    "def graph_top_brands_products():\n",
    "    brands=pd.DataFrame(df_final.brand.value_counts()).nlargest(10, 'brand').reset_index().rename(columns={'index':'Brands', 'brand':'Number of Products'})\n",
    "    fig, ax = plt.subplots(figsize=(20,15))\n",
    "    graph_brands = sns.barplot(data=brands, x='Brands', y='Number of Products')\n",
    "    plt.title('Products per brands'+ f' {cat_name}'+ '\\n', fontsize=20)    \n",
    "    return graph_brands\n",
    "    \n",
    "#creating graphs\n",
    "    \n",
    "def graph_subcat_promotions():\n",
    "    df_subcategory=pd.DataFrame(df_final.subcategory.value_counts()).reset_index().rename(columns={'index':'Subcategory', 'subcategory':'Number of Promotions'})\n",
    "    fig, ax = plt.subplots(figsize=(40,15))\n",
    "    graph_subcat = sns.barplot(data=df_subcategory, x='Subcategory', y='Number of Promotions')\n",
    "    plt.title('Promotions per subcategory'+ '\\n', fontsize=30)\n",
    "    return graph_subcat\n",
    "\n",
    "def graph_top_brands_promotions():\n",
    "    brands=pd.DataFrame(df_final.brand.value_counts()).nlargest(10, 'brand').reset_index().rename(columns={'index':'Brands', 'brand':'Number of Promotions'})\n",
    "    fig, ax = plt.subplots(figsize=(20,15))\n",
    "    graph_brands = sns.barplot(data=brands, x='Brands', y='Number of Promotions')\n",
    "    plt.title('Promotions per brands'+ '\\n', fontsize=20)    \n",
    "    return graph_brands\n",
    "\n",
    "#saving graphs\n",
    "\n",
    "def save_viz(barchart,title):\n",
    "    os.chdir('C:/Users/DELL/OneDrive - etu.unistra.fr/Bureau/cours fac/PROGRAMMATION PYTHON/PROJET/Output')\n",
    "    fig = barchart.get_figure()\n",
    "    fig.savefig(title+ '.png')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#calling functions\n",
    "if __name__ == '__main__':\n",
    "    scrap=type_scrapping()\n",
    "    if scrap == 'products':\n",
    "        cat_name=cat_name()\n",
    "        n=pages_number_products(cat_name)\n",
    "        df_final=scrapping_products()\n",
    "        df_final=resetting_index(df_final)\n",
    "        df_final=clean_cat(df_final)\n",
    "        df_final=renaming_col_products(df_final)\n",
    "        df_group=group_category_products(df_final)\n",
    "        save_df_products()\n",
    "        #graphs\n",
    "        subcat=graph_subcat_products()\n",
    "        top_brands=graph_top_brands_products()\n",
    "        #saving graphs\n",
    "        save_viz(subcat,f'Products per subcategory {cat_name}')\n",
    "        save_viz(top_brands, f'Products per brands (Top 10)  {cat_name}')\n",
    "\n",
    "    else:\n",
    "        n=pages_number_promotions('https://www.carrefour.fr/promotions?noRedirect=0&page=0')\n",
    "        df_final=scrapping_promotions()\n",
    "        df_final=resetting_index(df_final)\n",
    "        df_final=clean_cat(df_final)\n",
    "        df_final=renaming_col_promotions(df_final)\n",
    "        df_group=group_category_promotions(df_final)\n",
    "        save_df_promotions()\n",
    "        #graphs\n",
    "        subcat=graph_subcat_promotions()\n",
    "        top_brands=graph_top_brands_promotions()\n",
    "        #saving graphs\n",
    "        save_viz(subcat,'Promotions per subcategory' )\n",
    "        save_viz(top_brands, 'Promotion per brands (Top 10)')\n",
    "        #computing promos without lower price\n",
    "        dfnull=df_final.loc[df_final['difference'] == float(0)]\n",
    "        print(f\"There are {len(dfnull)} promotions without any discounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9d9bb7-50da-4484-8946-921e3d84b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Voulez-vous scraper les promotions ou les produits ? [promotions/products]  promotions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Aucun √©l√©ment <h5> trouv√©. Le site a peut-√™tre chang√©.\n",
      "Nombre de pages √† scraper pour les promotions : 1\n",
      "Scraping page promotion 1/1...\n",
      "Erreur sur la page 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 182\u001b[0m\n\u001b[0;32m    180\u001b[0m n \u001b[38;5;241m=\u001b[39m pages_number_promotions(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.carrefour.fr/promotions?noRedirect=0&page=0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre de pages √† scraper pour les promotions : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 182\u001b[0m df \u001b[38;5;241m=\u001b[39m scrap_promotions(n)\n\u001b[0;32m    183\u001b[0m save_to_csv(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarrefour_promotions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    184\u001b[0m show_promotion_graphs(df)\n",
      "Cell \u001b[1;32mIn[4], line 130\u001b[0m, in \u001b[0;36mscrap_promotions\u001b[1;34m(n_pages)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur sur la page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(all_data, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Web Scraper Carrefour - Version nettoy√©e et fonctionnelle\n",
    "# ---------------------------------------------------------------\n",
    "# Ce script permet de scraper les produits ou les promotions du site Carrefour,\n",
    "# de les nettoyer, analyser, et sauvegarder sous forme de fichier CSV et de graphiques.\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----------------------\n",
    "# CONFIGURATION A FAIRE\n",
    "# ----------------------\n",
    "# üö© A adapter selon ton ordinateur (le dossier de sauvegarde)\n",
    "OUTPUT_FOLDER = r\"C:/Users/DELL/OneDrive - etu.unistra.fr/Bureau/cours fac/PROGRAMMATION PYTHON/PROJET/Output\"\n",
    "\n",
    "# ----------------------\n",
    "# 1. Choix du type de scraping\n",
    "# ----------------------\n",
    "def type_scrapping():\n",
    "    while True:\n",
    "        scrap = input(\"Voulez-vous scraper les promotions ou les produits ? [promotions/products] \").strip()\n",
    "        if scrap in [\"promotions\", \"products\"]:\n",
    "            return scrap\n",
    "\n",
    "# ----------------------\n",
    "# 2. Liste des cat√©gories valides (produits)\n",
    "# ----------------------\n",
    "def choisir_categorie():\n",
    "    categories = [\n",
    "        'bio-et-ecologie', 'fruits-et-legumes', 'viandes-et-poissons',\n",
    "        'pains-et-patisseries', 'cremerie', 'traiteur', 'surgeles',\n",
    "        'epicerie-salee', 'epicerie-sucree', 'hygiene-et-beaute',\n",
    "        'boissons-sans-alcool', 'alcools-et-produits-aperitifs',\n",
    "        'entretien-et-nettoyage', 'animaux', 'le-monde-de-bebe',\n",
    "        'jardin-outdoor', 'maison-interieur', 'cuisine-et-arts-de-la-table',\n",
    "        'electromenager', 'bricolage-auto', 'beaute-entretien-et-proprete',\n",
    "        'bagagerie-sport-et-loisirs', 'telephonie-et-objets-connectes',\n",
    "        'image-et-son', 'informatique-bureau', 'culture-et-jeux-videos',\n",
    "        'jeux-et-jouets'\n",
    "    ]\n",
    "    print(\"Cat√©gories disponibles :\")\n",
    "    print(\"\\n\".join(categories))\n",
    "    while True:\n",
    "        cat = input(\"Quelle cat√©gorie voulez-vous scraper ? \").strip()\n",
    "        if cat in categories:\n",
    "            return cat\n",
    "\n",
    "# ----------------------\n",
    "# 3. Nombre de pages √† scraper (produits)\n",
    "# ----------------------\n",
    "def get_number_pages(cat):\n",
    "    url = f\"https://www.carrefour.fr/r/{cat}?noRedirect=1&page=0\"\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    try:\n",
    "        total_text = soup.select_one(\"h3\").text\n",
    "        total_count = int(total_text.strip().split()[0])\n",
    "        products_per_page = len(soup.select(\"ul h3\"))\n",
    "        return math.ceil(total_count / products_per_page)\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "# ----------------------\n",
    "# 4. Nombre de pages √† scraper (promotions)\n",
    "# ----------------------\n",
    "def pages_number_promotions(url):\n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    number = [i.text.replace('\\n', '') for i in soup.select('h3')]\n",
    "    if not number:\n",
    "        print(\"‚ùå Aucun √©l√©ment <h5> trouv√©. Le site a peut-√™tre chang√©.\")\n",
    "        return 1\n",
    "    i = int(number[0].split()[0])\n",
    "    product_name = [i.text.replace('\\n', '') for i in soup.select('ul h3')]\n",
    "    return math.ceil(i / len(product_name)) if product_name else 1\n",
    "\n",
    "# ----------------------\n",
    "# 5. Scraping des produits\n",
    "# ----------------------\n",
    "def scrap_products(cat, n_pages):\n",
    "    all_data = []\n",
    "    for i in range(n_pages):\n",
    "        url = f\"https://www.carrefour.fr/r/{cat}?noRedirect=1&page={i+1}\"\n",
    "        print(f\"Scraping page {i+1}/{n_pages}...\")\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers).json()\n",
    "            df = pd.json_normalize(res['data'])\n",
    "            df1 = df[[\n",
    "                'attributes.ean', 'attributes.title', 'attributes.brand',\n",
    "                'attributes.categories', 'attributes.availability.purchasable',\n",
    "                'attributes.price.price', 'attributes.price.perUnitLabel'\n",
    "            ]]\n",
    "            all_data.append(df1)\n",
    "        except:\n",
    "            print(f\"Erreur sur la page {i+1}\")\n",
    "        time.sleep(1)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# ----------------------\n",
    "# 6. Scraping des promotions\n",
    "# ----------------------\n",
    "def scrap_promotions(n_pages):\n",
    "    all_data = []\n",
    "    for i in range(n_pages):\n",
    "        url = f\"https://www.carrefour.fr/promotions?noRedirect=0&page={i+1}\"\n",
    "        print(f\"Scraping page promotion {i+1}/{n_pages}...\")\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers).json()\n",
    "            df = pd.json_normalize(res['data'])\n",
    "            df['difference'] = df['attributes.promotion.messageArgs.initialPrice'] - df['attributes.promotion.messageArgs.discountedPrice']\n",
    "            df1 = df[[\n",
    "                'attributes.ean', 'attributes.title', 'attributes.brand', 'attributes.categories',\n",
    "                'attributes.availability.purchasable', 'attributes.promotion.label',\n",
    "                'attributes.promotion.bestQuantity', 'attributes.promotion.messageArgs.discountedPrice',\n",
    "                'attributes.promotion.messageArgs.initialPrice', 'difference',\n",
    "                'attributes.promotion.discountLabel', 'attributes.price.perUnitLabel',\n",
    "                'attributes.promotion.promoStartDate', 'attributes.promotion.promoEndDate'\n",
    "            ]]\n",
    "            all_data.append(df1)\n",
    "        except:\n",
    "            print(f\"Erreur sur la page {i+1}\")\n",
    "        time.sleep(1)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# ----------------------\n",
    "# 7. Sauvegarde CSV\n",
    "# ----------------------\n",
    "def save_to_csv(df, filename):\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    df.to_csv(os.path.join(OUTPUT_FOLDER, filename), index=False)\n",
    "    print(f\"Donn√©es sauvegard√©es dans : {os.path.join(OUTPUT_FOLDER, filename)}\")\n",
    "\n",
    "# ----------------------\n",
    "# 8. Visualisations promotions\n",
    "# ----------------------\n",
    "def show_promotion_graphs(df):\n",
    "    df['category'] = df['attributes.categories'].apply(lambda x: x[0]['label'] if isinstance(x, list) and len(x) > 0 else \"Inconnu\")\n",
    "    df['subcategory'] = df['attributes.categories'].apply(lambda x: x[1]['label'] if isinstance(x, list) and len(x) > 1 else \"Inconnu\")\n",
    "\n",
    "    # Graphique : Promotions par sous-cat√©gorie\n",
    "    subcat_counts = df['subcategory'].value_counts().reset_index()\n",
    "    subcat_counts.columns = ['Subcategory', 'Number of Promotions']\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(data=subcat_counts.head(10), x='Subcategory', y='Number of Promotions')\n",
    "    plt.title(\"Top 10 des sous-cat√©gories avec le plus de promotions\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Graphique : Marques les plus repr√©sent√©es\n",
    "    top_brands = df['attributes.brand'].value_counts().reset_index().head(10)\n",
    "    top_brands.columns = ['Brand', 'Number of Promotions']\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(data=top_brands, x='Brand', y='Number of Promotions')\n",
    "    plt.title(\"Top 10 des marques en promotion\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------\n",
    "# 9. Programme principal\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    type_scrap = type_scrapping()\n",
    "    if type_scrap == \"products\":\n",
    "        cat = choisir_categorie()\n",
    "        n = get_number_pages(cat)\n",
    "        df = scrap_products(cat, n)\n",
    "        save_to_csv(df, f\"carrefour_products_{cat}.csv\")\n",
    "    else:\n",
    "        n = pages_number_promotions(\"https://www.carrefour.fr/promotions?noRedirect=0&page=0\")\n",
    "        print(f\"Nombre de pages √† scraper pour les promotions : {n}\")\n",
    "        df = scrap_promotions(n)\n",
    "        save_to_csv(df, \"carrefour_promotions.csv\")\n",
    "        show_promotion_graphs(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bcb003-44a0-440b-b0a8-5eb2b97dbe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
